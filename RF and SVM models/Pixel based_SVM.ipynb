{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b266800-293b-41b7-b4f4-26f4383a120a",
   "metadata": {},
   "source": [
    "# Project title:- \n",
    "Advancing Earth Observation Data and ResUNet-Deep Learning Model for Irrigated Area Mapping: The Case of Along the Awash Valley, Ethiopia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10616b-448e-4299-8083-bd6dbdf75408",
   "metadata": {},
   "source": [
    "\n",
    "# Pixel Based Image Classification (PBIC) using Support Vector Machine (SVM) classifier\n",
    "\n",
    "This Jupyter notebook demonstrates how to apply PBIC using RF classifier  with the ESA EO-Africa inovation lab cloud computing environment.\n",
    "\n",
    "**Prerequisites for running this notebook**\n",
    "\n",
    "Several packages need to be installed and/or imported for running this script:\n",
    "\n",
    "The `rasterio, geopandas,sklearn,and numpy` modules should be installed first to apply PBIC based RF classifier ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565ba5e-e40c-4c50-ad8e-199f801772ed",
   "metadata": {},
   "source": [
    "### Import Relevant Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01ad988-0736-49e5-9049-76e5652e2519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01537d32-d046-479b-b85e-3e7d2ca051ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc942e-cd4e-4ea7-acef-dd96c939deea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentinel_image_path = \"/home/eoafrica/Sentinel2_AWbasin/outputs_rgb/stacked_rgb.tif\"\n",
    "with rasterio.open(sentinel_image_path) as src:\n",
    "    sentinel_image = src.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377849a0-c4cb-4d2b-9486-9ca23ddaeba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load ground truth GCP shapefile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0fb4f-2d6a-443f-bf52-a0733eae6629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcp_shapefile_path = \"/home/eoafrica/Sentinel2_AWbasin/GCP_LULCawash/lulcgcp.shp\"\n",
    "gcp_data = gpd.read_file(gcp_shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a9a06-18c2-4138-8dff-18ca02573b22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract the values of the image pixels at the locations of the GCPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ceae9-081f-46e6-8507-0535113c9647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcp_points = gcp_data.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n",
    "gcp_values = []\n",
    "for point in gcp_points:\n",
    "    row, col = src.index(point[0], point[1])\n",
    "    gcp_values.append(sentinel_image[:, row, col])\n",
    "\n",
    "gcp_values = np.array(gcp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12adf5-687b-476b-84fd-b255ccddb9a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract corresponding class labels from the GCP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c3f3a-b679-4346-a8c4-695cca6b5f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = gcp_data[\"class_labe\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c9366-06fc-493b-a3ae-d5b1a53fdfea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6cccd-c4d0-4726-b7f0-7927787ac125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(gcp_values, class_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0850e3d-2f30-427d-8440-1fdd48877d88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1a43c-a4f9-4a49-895d-c4c469399223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f74c5f-f4d5-455e-a25c-f8dba73fbe7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4c63b-852e-46e7-aa7b-e95601ecadac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe3ecf-0861-4c1d-9f32-c6cd9765148a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cae9a-0b6c-4bc5-bb40-0d4d554ce39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1624a1-31cd-4bf6-91c3-c2c608f02184",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classify the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea286389-d1df-4947-b848-174e6aefb7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_image = np.zeros_like(sentinel_image[0])    \n",
    "for i in range(sentinel_image.shape[1]):\n",
    "    for j in range(sentinel_image.shape[2]):\n",
    "        pixel_values = sentinel_image[:, i, j].reshape(1, -1)\n",
    "        predicted_class = clf.predict(pixel_values)\n",
    "        predicted_image[i, j] = predicted_class    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac6aab-7172-4121-93de-02deee33889b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the classified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd024de-1877-40ff-bd89-3afea935b14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classified_image_path = \"/home/eoafrica/Sentinel2_AWbasin/RF_LULCresult/classified_image.tif\"  # Path to save the classified image\n",
    "with rasterio.open(classified_image_path, 'w', **src.profile) as dst:\n",
    "    dst.write(classified_image.astype(rasterio.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30de3a2-3a95-4d29-974f-a42b413d3a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
